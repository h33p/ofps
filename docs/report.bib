@book{hartley_zisserman_2004, place={Cambridge}, edition={2}, title={Multiple View Geometry in Computer Vision}, DOI={10.1017/CBO9780511811685}, publisher={Cambridge University Press}, author={Hartley, Richard and Zisserman, Andrew}, year={2004}}

@INPROCEEDINGS{8578130,
  author={Barath, Daniel},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Five-Point Fundamental Matrix Estimation for Uncalibrated Cameras}, 
  year={2018},
  volume={},
  number={},
  pages={235-243},
  doi={10.1109/CVPR.2018.00032}}

@INPROCEEDINGS{1211470,
  author={Nister, D.},
  booktitle={2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.}, 
  title={An efficient solution to the five-point relative pose problem}, 
  year={2003},
  volume={2},
  number={},
  pages={II-195},
  doi={10.1109/CVPR.2003.1211470}}

@article{tao2012simpleflow,
  author = {Tao, Michael and Bai, Jiamin and Kohli, Pushmeet and Paris, Sylvain},
  title = {SimpleFlow: A Non-iterative, Sublinear Optical Flow Algorithm},
  year = {2012},
  month = {May},
  abstract = {Optical flow is a critical component of video editing applications, e.g. for tasks such as object tracking, segmentation, and selection. In this paper, we propose an optical flow algorithm called SimpleFlow whose running times increase sublinearly in the number of pixels. Central to our approach is a probabilistic representation of the motion flow that is computed using only local evidence and without resorting to global optimization. To estimate the flow in image regions where the motion is smooth, we use a sparse set of samples only, thereby avoiding the expensive computation inherent in traditional dense algorithms. We show that our results can be used as is for a variety of video editing tasks. For applications where accuracy is paramount, we use our result to bootstrap a global optimization. This significantly reduces the running times of such methods without sacrificing accuracy. We also demonstrate that the SimpleFlow algorithm can process HD and 4K footage in reasonable times.},
  publisher = {John Wiley & Sons, Inc.},
  url = {https://www.microsoft.com/en-us/research/publication/simpleflow-non-iterative-sublinear-optical-flow-algorithm-2/},
  pages = {345-353},
  journal = {Computer Graphics Forum},
  volume = {31},
}

@inproceedings{rlof,
  author = {Geistert, Jonas and Senst, Tobias and Sikora, Thomas},
  year = {2016},
  month = {01},
  pages = {1-5},
  title = {Robust local optical flow: Dense motion vector field interpolation},
  doi = {10.1109/PCS.2016.7906352}
}

@inproceedings{lucas-kanade,
  author = {Lucas, Bruce D. and Kanade, Takeo},
  title = {An Iterative Image Registration Technique with an Application to Stereo Vision},
  year = {1981},
  publisher = {Morgan Kaufmann Publishers Inc.},
  booktitle = {Proceedings of the 7th International Joint Conference on Artificial Intelligence - Volume 2},
  pages = {674–679},
  numpages = {6},
  location = {Vancouver, BC, Canada},
  series = {IJCAI'81},
  doi = {10.5555/1623264.1623280}
}

@misc{cglue, author={Blažulionis, Aurimas}, title = {CGlue - Rust ABI safe code generator}, url = {https://github.com/h33p/cglue}}

@misc{youtube, author={YouTube}, title = {Recommended upload encoding settings}, url = {https://support.google.com/youtube/answer/1722171?hl=en#zippy=\%2Cvideo-codec-h\%2Cbitrate}}

@misc{randomize-layout, author={Rust compiler team}, title = {Add the -Z randomize-layout flag}, url = {https://github.com/rust-lang/compiler-team/issues/457}}

@misc{rust_sync_channel, author={Rust language}, title = {sync\_channel documentation}, url = {https://doc.rust-lang.org/std/sync/mpsc/fn.sync_channel.html}}

@misc{abi-ip, author={Rust ABI Wiki}, title = {Proposing a stable modularizable ABI interface for Rust}, url = {https://github.com/slightknack/rust-abi-wiki/blob/7c63caa58c83cb33f52038d40a16fff62517900d/src/intro/initial_proposal.md}}

@misc{egui, author={Emil Ernerfeldt}, title = {egui}, url = {https://github.com/emilk/egui}}

@misc{libav-patch, author={Carl Eugen}, title = {[Libav-user] motion vectors extraction}, url = {https://ffmpeg.org/pipermail/libav-user/2016-December/009913.html}}

@misc{rayon, author={Rayon team}, title = {Rayon repository}, url = {https://github.com/rayon-rs/rayon}}

@misc{webgpu, author={W3C}, title = {WebGPU}, url = {https://gpuweb.github.io/gpuweb/}}

@misc{av1, author={Alliance for Open Media}, title = {AV1 Standard}, url = {https://aomediacodec.github.io/av1-spec/av1-spec.pdf}}

@misc{av1_global_motion, author={Alliance for Open Media}, title = {Global Motion Compensation}, url = {https://github.com/AOMediaCodec/SVT-AV1/blob/master/Docs/Appendix-Global-Motion.md}}

@misc{h264, author={ITU-T}, title = {Advanced video coding for generic audiovisual services}, url = {https://www.itu.int/rec/T-REC-H.264}}

@misc{h265, author={ITU-T}, title = {High efficiency video coding}, url = {https://www.itu.int/rec/T-REC-H.265}}

@misc{opencv5calib, author={OpenCV}, title = {Camera Calibration and 3D Reconstruction}, url = {https://docs.opencv.org/3.0-beta/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html}}

@misc{libmv, author={Blender}, title = {Libmv}, url = {https://developer.blender.org/tag/libmv/}}

@misc{blender-motion-tracking, author={Blender}, title = {Motion Tracking Introduction}, url = {https://docs.blender.org/manual/en/latest/movie_clip/tracking/introduction.html}}

@misc{libmv-fork, author={Aurimas Blažulionis}, title = {Libmv fork}, url = {https://github.com/h33p/libmv}}

@inproceedings{zhao2020maskflownet,
  author = {Zhao, Shengyu and Sheng, Yilun and Dong, Yue and Chang, Eric I-Chao and Xu, Yan},
  title = {MaskFlownet: Asymmetric Feature Matching with Learnable Occlusion Mask},
  booktitle = {CVPR 2020},
  year = {2020},
  month = {04},
  doi = {10.48550/arXiv.2003.10955},
}

@article{voldor,
  author = {Min, Zhixiang and Yang, Yiding and Dunn, Enrique},
  year = {2021},
  month = {04},
  title = {VOLDOR: Visual Odometry from Log-logistic Dense Optical flow Residuals},
  doi = {10.48550/arXiv.2104.06789},
}

@INPROCEEDINGS{1334181,
  author={Ewerth, R. and Schwalb, M. and Tessmann, P. and Freisleben, B.},
  booktitle={Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.}, 
  title={Estimation of arbitrary camera motion in MPEG videos}, 
  year={2004},
  volume={1},
  number={},
  pages={512-515 Vol.1},
  doi={10.1109/ICPR.2004.1334181}}

@InProceedings{almeida,
author="Almeida, Jurandy
and Minetto, Rodrigo
and Almeida, Tiago A.
and da S. Torres, Ricardo
and Leite, Neucimar J.",
editor="Bebis, George
and Boyle, Richard
and Parvin, Bahram
and Koracin, Darko
and Kuno, Yoshinori
and Wang, Junxian
and Wang, Jun-Xuan
and Wang, Junxian
and Pajarola, Renato
and Lindstrom, Peter
and Hinkenjann, Andr{\'e}
and Encarna{\c{c}}{\~a}o, Miguel L.
and Silva, Cl{\'a}udio T.
and Coming, Daniel",
title="Robust Estimation of Camera Motion Using Optical Flow Models",
booktitle="Advances in Visual Computing",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="435--446",
abstract="The estimation of camera motion is one of the most important aspects for video processing, analysis, indexing, and retrieval. Most of existing techniques to estimate camera motion are based on optical flow methods in the uncompressed domain. However, to decode and to analyze a video sequence is extremely time-consuming. Since video data are usually available in MPEG-compressed form, it is desirable to directly process video material without decoding. In this paper, we present a novel approach for estimating camera motion in MPEG video sequences. Our technique relies on linear combinations of optical flow models. The proposed method first creates prototypes of optical flow, and then performs a linear decomposition on the MPEG motion vectors, which is used to estimate the camera parameters. Experiments on synthesized and real-world video clips show that our technique is more effective than the state-of-the-art approaches for estimating camera motion in MPEG video sequences.",
isbn="978-3-642-10331-5"
}

@ARTICLE{825867,
  author={Yap-Peng Tan and Saur, D.D. and Kulkami, S.R. and Ramadge, P.J.},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Rapid estimation of camera motion from compressed video with application to video annotation}, 
  year={2000},
  volume={10},
  number={1},
  pages={133-146},
  doi={10.1109/76.825867}}


@INPROCEEDINGS{1414440,
  author={Gillespie, W.J. and Nguyen, D.T.},
  booktitle={2004 IEEE Region 10 Conference TENCON 2004.}, 
  title={Robust estimation of camera motion in MPEG domain}, 
  year={2004},
  volume={A},
  number={},
  pages={395-398 Vol. 1},
  doi={10.1109/TENCON.2004.1414440}}

@inproceedings{Farnebck2003TwoFrameME,
  title={Two-Frame Motion Estimation Based on Polynomial Expansion},
  author={Gunnar Farneb{\"a}ck},
  booktitle={SCIA},
  year={2003}
}

@incollection{FISCHLER1987726,
  title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
  editor = {Martin A. Fischler and Oscar Firschein},
  booktitle = {Readings in Computer Vision},
  publisher = {Morgan Kaufmann},
  address = {San Francisco (CA)},
  pages = {726-740},
  year = {1987},
  isbn = {978-0-08-051581-6},
  doi = {https://doi.org/10.1016/B978-0-08-051581-6.50070-2},
  url = {https://www.sciencedirect.com/science/article/pii/B9780080515816500702},
  author = {Martin A. Fischler and Robert C. Bolles},
}
