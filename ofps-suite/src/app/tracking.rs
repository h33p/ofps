use super::utils::camera_controller::CameraController;
use super::{
    CreateDecoderUiState, CreateEstimatorUiState, CreatePluginUi, OfpsAppContext, OfpsCtxApp,
};
use egui::*;
use epi::Frame;
use nalgebra as na;
use ofps::prelude::v1::*;
use std::sync::{atomic::Ordering, Arc};
use wimrend::material::Material;
use wimrend::mesh::Mesh;
use wimrend::Renderer;

mod worker;

use worker::{FrameState, TrackingSettings, TrackingState, TrackingWorker};

pub struct MotionTrackingApp {
    create_decoder_state: CreateDecoderUiState,
    app_state: Option<TrackingWorker>,
    app_settings: TrackingSettings,
    estimator_uis: Vec<CreateEstimatorUiState>,
    cube_material: Option<Arc<Material>>,
    camera_controller: CameraController,
}

impl Default for MotionTrackingApp {
    fn default() -> Self {
        Self {
            create_decoder_state: Default::default(),
            app_state: None,
            app_settings: Default::default(),
            estimator_uis: vec![],
            cube_material: None,
            camera_controller: Default::default(),
        }
    }
}

impl MotionTrackingApp {
    fn tracking_step(&mut self, renderer: &mut Renderer) {
        if let Some(state) = &self.app_state {
            // Load up any frames generated by worker onto GPU.
            for frame in state.frames_to_load.try_iter() {
                if let Ok(mut frame) = frame.lock() {
                    let frame = &mut *frame;
                    match frame {
                        FrameState::Pending(buf, height) => {
                            if let Ok(texture) = renderer.texture_from_rgba(
                                None,
                                bytemuck::cast_slice(&buf),
                                *height,
                            ) {
                                *frame = FrameState::Loaded(
                                    Material::textured(
                                        renderer.pipeline_manager_mut(),
                                        texture.into(),
                                    )
                                    .into(),
                                )
                            } else {
                                *frame = FrameState::Pending(vec![], 0);
                            }
                        }
                        _ => {}
                    }
                }
            }
        }
    }

    fn render(&mut self, renderer: &mut Renderer) {
        let cube_material = if let Some(cube_material) = self.cube_material.clone() {
            cube_material
        } else {
            let cube_material = Arc::new(Material::unlit(renderer.pipeline_manager_mut()));
            self.cube_material = Some(cube_material.clone());
            cube_material
        };

        self.camera_controller.on_render(renderer);

        let start = na::matrix![0.0; 0.0; 0.0].into();

        let end = na::matrix![6.0; 2.0; 4.0].into();

        renderer.line(start, end, 4.0, na::matrix![1.0; 0.0; 0.0; 1.0]);

        let range = 10isize;

        let line_colour = na::matrix![0.1; 0.1; 0.1; 1.0];
        let line_thickness = 2.0;

        for v in -range..=range {
            let v = v as f32;
            let range = range as f32;
            renderer.line(
                na::matrix![v; -range; 0.0].into(),
                na::matrix![v; range; 0.0].into(),
                line_thickness,
                line_colour,
            );
            renderer.line(
                na::matrix![-range; v; 0.0].into(),
                na::matrix![range; v; 0.0].into(),
                line_thickness,
                line_colour,
            );
        }

        let (offset_factor, x_scale) = {
            let intrinsics = self.app_settings.camera.intrinsics();
            (
                intrinsics[(1, 1)] * 0.5,
                intrinsics[(1, 1)] / intrinsics[(0, 0)],
            )
        };

        if let Some(Ok(app_state)) = self.app_state.as_ref().map(|a| a.worker.read()) {
            for (state, settings) in app_state
                .estimators
                .iter()
                .zip(self.app_settings.settings.iter())
                .filter_map(|(v, (_, _, s))| v.as_ref().zip(Some(s)))
            {
                let scale = settings.camera_offset / offset_factor;

                for (pos, rot, mat) in state.layered_frames() {
                    if let Ok(mat) = mat.lock() {
                        if let FrameState::Loaded(mat) = &*mat {
                            renderer.obj(
                                Mesh::centered_quad(),
                                (pos * settings.scale_factor)
                                    + rot * na::matrix![0.0; settings.camera_offset; 0.0],
                                rot * na::UnitQuaternion::from_euler_angles(
                                    -90.0f32.to_radians(),
                                    0.0,
                                    0.0,
                                ),
                                na::matrix![x_scale * scale; scale; 1.0],
                                na::matrix![1.0; 1.0; 1.0; 1.0],
                                mat.clone(),
                            );
                        }
                    }
                }
            }
        }
    }
}

impl OfpsCtxApp for MotionTrackingApp {
    fn name(&self) -> &str {
        "Tracking"
    }

    fn update(
        &mut self,
        ctx: &Context,
        ofps_ctx: &Arc<OfpsAppContext>,
        frame: &Frame,
        renderer: &mut Renderer,
    ) {
        self.tracking_step(renderer);
        self.camera_controller.update(ctx);

        self.render(renderer);

        egui::SidePanel::left("tracking_settings").show(ctx, |ui| {
            egui::trace!(ui);

            ui.vertical_centered(|ui| {
                ui.heading("Tracking");
            });

            ui.separator();

            ui.heading("Decoder:");

            ui.separator();

            if let Some(_) = &mut self.app_state {
                if ui.button("Close decoder").clicked() {
                    self.app_state = None;
                }
            } else {
                match DecoderPlugin::create_plugin_ui(
                    ui,
                    ofps_ctx,
                    &mut self.create_decoder_state,
                    0,
                    |_| {},
                ) {
                    Some(Ok(decoder)) => {
                        self.app_state =
                            Some(TrackingState::worker(decoder, self.app_settings.clone()))
                    }
                    _ => {}
                }
            }

            ui.separator();

            ui.heading("Estimators:");

            ui.separator();

            let mut to_remove = None;

            {
                for (i, (state, (est, exists, settings))) in self
                    .estimator_uis
                    .iter_mut()
                    //.zip(app_state.estimators.iter())
                    .zip(self.app_settings.settings.iter_mut())
                    .enumerate()
                {
                    let is_some = exists.load(Ordering::Relaxed);

                    Grid::new(format!("estimator_ui_{i}")).show(ui, |ui| {
                        ui.label(format!("Estimator #{}", i));
                        ui.end_row();

                        ui.checkbox(&mut settings.layer_frames, "Draw frames");
                        ui.end_row();
                        ui.label("Angle delta");
                        ui.add(
                            Slider::new(&mut settings.layer_angle_delta, 0.01..=90.0)
                                .step_by(0.01)
                                .logarithmic(true),
                        );
                        ui.end_row();

                        ui.label("Keep frames");
                        ui.add(Slider::new(&mut settings.keep_frames, 1..=1000));
                        ui.end_row();

                        ui.label("Position scale");
                        ui.add(Slider::new(&mut settings.scale_factor, 0.00..=10.0));
                        ui.end_row();

                        ui.label("Frame offset");
                        ui.add(
                            Slider::new(&mut settings.camera_offset, 0.00..=100.0).step_by(0.01),
                        );
                        ui.end_row();

                        if is_some {
                            if ui.button("Stop").clicked() {
                                *est.lock().unwrap() = None;
                                exists.store(false, Ordering::Relaxed);
                            }
                            if ui.button("Remove").clicked() {
                                to_remove = Some(i);
                            }
                            ui.end_row();
                        }
                    });

                    if !is_some {
                        match EstimatorPlugin::create_plugin_ui(ui, ofps_ctx, state, i + 1, |ui| {
                            if ui.button("Remove").clicked() {
                                to_remove = Some(i);
                            }
                        }) {
                            Some(Ok(new_estimator)) => {
                                *est.lock().unwrap() = Some(new_estimator);
                                exists.store(true, Ordering::Relaxed);
                            }
                            _ => {}
                        }
                    }

                    ui.separator();
                }

                if let Some(to_remove) = to_remove {
                    self.app_settings.settings.remove(to_remove);
                    self.estimator_uis.remove(to_remove);
                }

                if ui.button("New estimator").clicked() {
                    self.app_settings.settings.push(Default::default());
                    self.estimator_uis.push(Default::default());
                }

                if let Some(Ok(mut settings)) = self.app_state.as_ref().map(|a| a.worker.settings())
                {
                    *settings = self.app_settings.clone();
                }
            }
        });
    }
}
